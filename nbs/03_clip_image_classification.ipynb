{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "03_clip_image_classification.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq27n1D-6u77"
      },
      "source": [
        "# CLIP vs ResNext Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFL4IWSY6u8D"
      },
      "source": [
        "#### Reference\n",
        "\n",
        "- https://github.com/openai/CLIP\n",
        "- https://openai.com/blog/clip/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqsjGNnP6u8D"
      },
      "source": [
        "COLAB = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCnKRXWB6u8E"
      },
      "source": [
        "## Install the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZMgqB_R6u8E",
        "outputId": "a8e29cf1-37f6-434b-f772-724c7d35da5a"
      },
      "source": [
        "if COLAB:\n",
        "  # --- Remember to change the runtime to use GPU for better performance\n",
        "  !nvidia-smi\n",
        "  !pip install -Uqq ftfy regex tqdm \n",
        "  !rm -rf jupyter-notebooks && git clone https://github.com/alpha2phi/jupyter-notebooks.git \n",
        "  !rm -rf CLIP && cp -R jupyter-notebooks/nbs/CLIP .\n",
        "  !rm -rf test_data && cp -R jupyter-notebooks/nbs/test_data .\n",
        "else:\n",
        "  !pip install -Uqq ftfy regex tqdm torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jan 11 15:50:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 727kB 17.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.1MB/s \n",
            "\u001b[?25h  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into 'jupyter-notebooks'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 54 (delta 13), reused 47 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1CXxlPa6u8F"
      },
      "source": [
        "## Import Libaries and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lmQKfdD6u8F",
        "outputId": "00863980-c6ce-449a-cb60-1886d61556d3"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "from CLIP import clip\n",
        "from PIL import Image\n",
        "\n",
        "# Load the model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load('ViT-B/32', device)\n",
        "\n",
        "print(f\"Device - {device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████| 353976522/353976522 [00:05<00:00, 60108148.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Device - cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dLTsWU46u8F"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBr1CQ8l6u8G"
      },
      "source": [
        "with open(\"CLIP/imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "\n",
        "def predict_clip(image_file_path):\n",
        "    image = preprocess(Image.open(image_file_path)).unsqueeze(0).to(device)\n",
        "    text = clip.tokenize(categories).to(device)\n",
        "\n",
        "    # Calculate features\n",
        "    with torch.no_grad():\n",
        "        image_features = model.encode_image(image)\n",
        "        text_features = model.encode_text(text)\n",
        "\n",
        "    # Pick the top 5 most similar labels for the image\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "    values, indices = similarity[0].topk(5)\n",
        "\n",
        "    print(\"\\nTop predictions:\\n\")\n",
        "    for value, index in zip(values, indices):\n",
        "        print(f\"{categories[index]:>16s}: {100 * value.item():.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHYJHuug6u8G",
        "outputId": "9bd79578-8975-4c39-dec5-85a885db1082"
      },
      "source": [
        "predict_clip(\"test_data/images/bear.jpg\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Top predictions:\n",
            "\n",
            "      brown bear: 92.33%\n",
            "American black bear: 5.21%\n",
            "        bearskin: 0.58%\n",
            "        ice bear: 0.30%\n",
            "      sloth bear: 0.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVCg1yuc6u8H",
        "outputId": "d54cc616-0066-4d2b-b939-db06c62862ac"
      },
      "source": [
        "predict_clip(\"test_data/images/bird.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Top predictions:\n",
            "\n",
            "  Scotch terrier: 0.68%\n",
            "wire-haired fox terrier: 0.45%\n",
            "          Loafer: 0.41%\n",
            "   parallel bars: 0.40%\n",
            "   Irish terrier: 0.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxzhqCysITHD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}